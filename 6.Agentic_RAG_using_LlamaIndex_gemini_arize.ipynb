{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1ME8m2EE3c4"
      },
      "source": [
        "# Agentic RAG in LlamaIndex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M4zgrIYtzEW"
      },
      "source": [
        "## Part 0: Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gpk5DaC8E3c9"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWLTDEbi4QVA",
        "outputId": "7051cb95-ea8c-4b86-afbd-3d935e28b526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-gemini in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-gemini) (0.14.5)\n",
            "Requirement already satisfied: pillow<11,>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-gemini) (10.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.36.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.26.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.185.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.10)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.8.3)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.0.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (4.5.0)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.0.44)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.12.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.17.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.14.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (8.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "pip install llama-index-llms-gemini llama-index-embeddings-huggingface google-generativeai sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vobdEXgquH-I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QysSnlVpE3c-"
      },
      "source": [
        "And, let's log in to Hugging Face to use serverless Inference APIs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "aed853987afa4b93ac1dc6ecffca0ac4",
            "4ac188960dd34f1cbc4d1448ba8a16a9",
            "be4590a7e2a8482da609231634e01e0b",
            "d15ffdad61ca433d8a73090d6cfae7eb",
            "62ce864c960e47d399042ccebf138f3b",
            "fbf66967720648f69ff873988ac17545",
            "5cf39d22fc1740208697b21add64d72d",
            "c3659927ebaf43e4924886c362426494",
            "491b47bff29942c2b3b23cfd222e011f",
            "9c237069abef4768b8727054b18a715d",
            "00cf10e3d6e8455980d5066118ea2526",
            "6d27293639884ff9a84ac607d23d02f1",
            "5bb095faf6b048388ae1e36c7d7b8796",
            "8894971591d948608ecfd50faa1b5d9c",
            "ae34b0dcac484743875ca296b4b8794f",
            "370c33105aa94482a9879cdaa237b3f1",
            "1792fb8e45b04cf2ad2f9b1b7b50c61a",
            "c20d9e3006ff40499b37f81a61f6aa21",
            "fba09e6dd0a34d47883326221bba0fe8",
            "b4a89ba3925e45eaa8312234ed61da59"
          ]
        },
        "id": "POMls8o8E3c-",
        "outputId": "26366711-32fe-498e-f093-3c1e5b2e1b93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aed853987afa4b93ac1dc6ecffca0ac4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz3QdNYCtU7u"
      },
      "source": [
        "## Part 1: Simple RAG Systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "e5n15_sB4G1h",
        "outputId": "5a681bc8-7978-4056-f5bc-a0c156a4e6f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 26 document(s).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2648729993.py:26: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
            "  Settings.llm = Gemini(model=\"models/gemini-2.5-flash\")\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.llms.gemini import Gemini  # New import for Gemini LLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding  # New import for local/HuggingFace embeddings\n",
        "import os\n",
        "# Make sure to install the necessary packages first:\n",
        "# pip install llama-index-llms-gemini llama-index-embeddings-huggingface google-generativeai sentence-transformers\n",
        "\n",
        "# Set your API Key for Gemini\n",
        "# It is highly recommended to set this as an environment variable (e.g., in a .env file or your shell)\n",
        "# export GOOGLE_API_KEY=\"YOUR_API_KEY\"\n",
        "# For demonstration, you might set it directly, but this is less secure:\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "\n",
        "# Load document\n",
        "reader = SimpleDirectoryReader(input_files=[\"state_of_AI.pdf\"])\n",
        "documents = reader.load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n",
        "\n",
        "# Split into chunks\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "\n",
        "# Set up LLM and embedding model\n",
        "# LLM: Use Gemini, specifying a model like \"models/gemini-pro\" or \"models/gemini-2.5-flash\"\n",
        "Settings.llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
        "\n",
        "# Embedding Model: Use HuggingFaceEmbedding for BGE-small-en\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\" # This is the standard BGE-small-en model name\n",
        ")\n",
        "\n",
        "# Create vector index\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "\n",
        "# Create query engine\n",
        "query_engine = vector_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUJReWButXJp",
        "outputId": "6b6642ac-6eb0-4d95-b75a-483852b54f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 26 document(s).\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "# Load document\n",
        "reader = SimpleDirectoryReader(input_files=[\"state.pdf\"])\n",
        "documents = reader.load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n",
        "\n",
        "# Split into chunks\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "\n",
        "# Set up LLM and embedding model\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Create vector index\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "\n",
        "# Create query engine\n",
        "query_engine = vector_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNDjd6WKAiGU"
      },
      "source": [
        "#### 1.1 Inspecting the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iipL_cCRAhAf",
        "outputId": "d7123033-1981-4009-df06-98537282fd17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of embeddings: 27\n",
            "Number of node references: 27\n",
            "\n",
            "--- Embedding 0 ---\n",
            "Node ID: 37433a3d-10f0-4e62-b871-442e5522532c\n",
            "Embedding dimension: 384\n",
            "First 10 values: [-0.0662464052438736, -0.027124036103487015, 0.03070172294974327, -0.002462257631123066, 0.03332288935780525, 0.030975334346294403, -0.022839121520519257, 0.04124998301267624, 0.0035174640361219645, -0.006849117111414671]\n",
            "\n",
            "--- Embedding 1 ---\n",
            "Node ID: 7538d787-0c9b-4df6-b35e-3ebad09db9f9\n",
            "Embedding dimension: 384\n",
            "First 10 values: [0.006492024287581444, -0.029223959892988205, 0.005867324769496918, -0.05067090690135956, 0.01823529414832592, 0.043149806559085846, -0.0011607427150011063, 0.017698295414447784, 0.03303244709968567, -0.005703154020011425]\n",
            "\n",
            "--- Embedding 2 ---\n",
            "Node ID: 1dcd7c99-c62e-4b80-a1bc-422652d7102a\n",
            "Embedding dimension: 384\n",
            "First 10 values: [0.026413721963763237, -0.015026451088488102, 0.013218114152550697, -0.05975547432899475, 0.049674130976200104, -0.005162168759852648, 0.03932492807507515, 0.032075706869363785, 0.017872989177703857, -0.0038603805005550385]\n"
          ]
        }
      ],
      "source": [
        "# Access the vector store data directly\n",
        "vector_store = vector_index.vector_store\n",
        "\n",
        "# Get embedding dictionary and node dictionary\n",
        "embedding_dict = vector_store.data.embedding_dict\n",
        "node_dict = vector_store.data.text_id_to_ref_doc_id\n",
        "\n",
        "print(f\"Number of embeddings: {len(embedding_dict)}\")\n",
        "print(f\"Number of node references: {len(node_dict)}\")\n",
        "\n",
        "# Show first few embeddings\n",
        "for i, (node_id, embedding) in enumerate(list(embedding_dict.items())[:3]):\n",
        "    print(f\"\\n--- Embedding {i} ---\")\n",
        "    print(f\"Node ID: {node_id}\")\n",
        "    print(f\"Embedding dimension: {len(embedding)}\")\n",
        "    print(f\"First 10 values: {embedding[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6caODl2LAkuf"
      },
      "source": [
        "#### 1.2 Asking questions to the RAG system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YQwyzi6StoOE",
        "outputId": "317b4f74-9a4d-4eac-9469-5673184b79c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lareina Yee is one of the individuals associated with \"The state of AI\" document, published in March 2025.\n"
          ]
        }
      ],
      "source": [
        "# Query the document\n",
        "response = query_engine.query(\"Who is Lareina Yee?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FrcVI5_AoKj"
      },
      "source": [
        "#### 1.3 Checking if the responses make sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzWW3i6d--cv",
        "outputId": "e43ecf53-0066-4452-e315-0ccae9737569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(len(response.source_nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSUGVGT1ACSL",
        "outputId": "9db84417-1ea6-4ce1-a96c-71527f90a1eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source nodes:\n",
            "==================================================\n",
            "Node 1:\n",
            "Score: 0.47403650633360583\n",
            "Text: The state of AI  \n",
            "March 2025\n",
            "Alex Singla  \n",
            "Alexander Sukharevsky  \n",
            "Lareina Yee  \n",
            "Michael Chui  \n",
            "Bryce Hall\n",
            "How organizations are rewiring to capture value\n",
            "Metadata: {'page_label': '1', 'file_name': 'state_of_AI.pdf', 'file_path': 'state_of_AI.pdf', 'file_type': 'application/pdf', 'file_size': 5564174, 'creation_date': '2025-10-24', 'last_modified_date': '2025-10-24'}\n",
            "------------------------------\n",
            "Node 2:\n",
            "Score: 0.4416760088006249\n",
            "Text: McKinsey & Company\n",
            "16\n",
            "14\n",
            "8\n",
            "18\n",
            "40\n",
            "4\n",
            "16\n",
            "26\n",
            "13 20\n",
            "16\n",
            "2\n",
            "30\n",
            "35\n",
            "8\n",
            "28\n",
            "5\n",
            "16\n",
            "14\n",
            "10\n",
            "15\n",
            "42\n",
            "3 34\n",
            "15\n",
            "28\n",
            "12 22\n",
            "12\n",
            "26\n",
            "31\n",
            "10\n",
            "30\n",
            "7\n",
            "20\n",
            "16\n",
            "7\n",
            "19\n",
            "35\n",
            "4\n",
            "23\n",
            "24\n",
            "8\n",
            "20\n",
            "21\n",
            "24\n",
            "39\n",
            "5\n",
            "32\n",
            "3\n",
            "13\n",
            "16\n",
            "8\n",
            "18\n",
            "42\n",
            "15\n",
            "26\n",
            "15 20\n",
            "15\n",
            "33\n",
            "33\n",
            "8\n",
            "24\n",
            "6\n",
            "18\n",
            "18\n",
            "7\n",
            "17\n",
            "37\n",
            "3\n",
            "16\n",
            "34\n",
            "9\n",
            "21\n",
            "15\n",
            "32\n",
            "31\n",
            "7\n",
            "26\n",
            "6\n",
            "24\n",
            "22\n",
            "5\n",
            "11\n",
            "36\n",
            "3\n",
            "17\n",
            "31\n",
            "15\n",
            "22\n",
            "21\n",
            "2\n",
            "36\n",
            "32\n",
            "4\n",
            "19\n",
            "21\n",
            "17\n",
            "6\n",
            "18\n",
            "9\n",
            "30\n",
            "20\n",
            "22\n",
            "15 18\n",
            "15\n",
            "31\n",
            "28\n",
            "12\n",
            "27\n",
            "5\n",
            "5\n",
            "4 32\n",
            "Personal experience with gen AI tools, in 2023, /f_irst half of 2024, and second half of 2024,¹ % of respondents\n",
            "Respondents are much more likely now than in 2023 and in early 2024 to say they are \n",
            "using gen AI.\n",
            "Regularly use\n",
            "for work\n",
            "Regularly use for work\n",
            "and outside of work\n",
            "Regularly use \n",
            "outside of work\n",
            "Have tried\n",
            "at least once\n",
            "No exposure Don’t know\n",
            "Born\n",
            "1981/endash.case96³\n",
            "Born\n",
            "1965/endash.case80³\n",
            "Born in 1964\n",
            "or earlier³\n",
            "Average\n",
            "overall¹\n",
            "Midlevel\n",
            "managers²\n",
            "Senior\n",
            "managers²\n",
            "C-level\n",
            "executives²\n",
            "Note: Figures may not sum to 100%, because of rounding. \n",
            "¹In 2023, n = 1,684; in part 1 of 2024, n = 1,363; in part 2 of 2024, n = 1,491.\n",
            "²In 2023, C-level respondents, n = 541; senior managers, n = 437; and midlevel managers, n = 339. In Feb–Mar 2024, C-level respondents, n = 474; senior managers, n = 406; and \n",
            "midlevel managers, n = 206. In July 2024, C-level respondents, n = 555; senior managers, n = 371; and midlevel managers, n = 264.\n",
            "³In 2023, for respondents born in 1964 or earlier, n = 143; for respondents born 1965–80, n = 268; and for respondents born 1981–96, n = 80. In 2024, for respondents born in 1964 \n",
            "or earlier, n = 158; for respondents born 1965–80, n = 331; and for respondents born 1981–96, n = 184. In 2024 part 2, for respondents born in 1964 or earlier, n = 171; for \n",
            "respondents born 1965–80, n = 398; and for respondents born 1981–96, n = 218. Age details were not available for all respondents. \n",
            "Source: McKinsey Global Surveys on the state of AI, 2023–24\n",
            "2023 20242024\n",
            "18The state of AI: How organizations are rewiring to capture value\n",
            "C-level executives \n",
            "are using gen AI \n",
            "more than others\n",
            " \n",
            "Individual use of gen AI by our respondents also increased \n",
            "significantly in 2024, with C-level executives leading the \n",
            "way (exhibit). Fifty-three percent of surveyed executives \n",
            "say they are regularly using gen AI at work, compared with \n",
            "44 percent of midlevel managers. While we see variation in \n",
            "individuals’ use of gen AI across industries and regions, the \n",
            "data largely show widening use across the board. \n",
            "Exhibit\n",
            "Metadata: {'page_label': '19', 'file_name': 'state_of_AI.pdf', 'file_path': 'state_of_AI.pdf', 'file_type': 'application/pdf', 'file_size': 5564174, 'creation_date': '2025-10-24', 'last_modified_date': '2025-10-24'}\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Print out each source node\n",
        "print(\"Source nodes:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, node in enumerate(response.source_nodes):\n",
        "    print(f\"Node {i+1}:\")\n",
        "    print(f\"Score: {node.score}\")\n",
        "    print(f\"Text: {node.text}\")\n",
        "    print(f\"Metadata: {node.metadata}\")\n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "I59dl1cstpOY",
        "outputId": "dbb62a2d-97e3-4889-93ae-250c75250cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Organizations are generally in the early stages of adopting and scaling generative AI (gen AI) solutions, with only a small percentage of executives describing their rollouts as mature. Many have yet to experience organization-wide, bottom-line impact from gen AI use.\n",
            "\n",
            "Key findings include:\n",
            "*   There are 12 identified adoption and scaling practices for gen AI, all of which show positive correlations with EBIT impact.\n",
            "*   Tracking well-defined Key Performance Indicators (KPIs) for gen AI solutions is the practice with the most significant impact on the bottom line. For larger organizations, establishing a clearly defined road map to drive gen AI adoption also has a substantial impact.\n",
            "*   Overall, less than one-third of organizations are following most of these 12 adoption and scaling practices. For instance, less than one in five organizations are tracking KPIs for gen AI solutions.\n",
            "*   Larger organizations are more likely to implement these best practices compared to smaller organizations. They are notably more advanced in areas such as establishing dedicated teams for gen AI adoption, creating clear road maps, utilizing internal communications about gen AI's value, providing role-based capability training, and developing comprehensive approaches to foster customer trust in gen AI.\n"
          ]
        }
      ],
      "source": [
        "# Ask more questions\n",
        "response2 = query_engine.query(\"What are the main findings about AI adoption?\")\n",
        "print(response2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "pu_T0jLStqU-",
        "outputId": "c13eee0e-69d0-40d4-9495-ffdae8581249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Organizations are actively working to mitigate risks associated with generative AI. There is an increasing focus on addressing risks such as inaccuracy, intellectual property infringement, and privacy. Many organizations are intensifying their efforts to manage these and other gen-AI-related risks.\n",
            "\n",
            "Specifically, organizations are more likely than in early 2024 to be actively managing risks related to inaccuracy, cybersecurity, and intellectual property infringement. These three are among the risks most frequently cited as having caused negative consequences for organizations. A survey indicates that 47 percent of organizations have experienced at least one negative consequence from gen AI use, an increase from 44 percent in early 2024.\n",
            "\n",
            "Other identified risks include regulatory compliance, personal/individual privacy, explainability, workforce/labor displacement, equity and fairness, organizational reputation, national security, physical safety, environmental impact, and political stability.\n"
          ]
        }
      ],
      "source": [
        "response3 = query_engine.query(\"What does the document say about AI risks?\")\n",
        "print(response3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1T80meUE3dA"
      },
      "source": [
        "## Part 2: Agentic RAG\n",
        "\n",
        "Let's now upgrade the previously defined RAG system into an Agentic RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsJGdIJ3afAH",
        "outputId": "4e671926-5e37-457a-f4cc-d8d4aa8fb27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade datasets\n",
        "!pip install --upgrade huggingface-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAHJ_2iLt-gH"
      },
      "source": [
        "#### 2.1: Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju5oAHyNX7du",
        "outputId": "ab5be195-e2ad-4788-c0a2-ce1f837f4a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 26 document(s).\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "reader = SimpleDirectoryReader(input_files=[\"state_of_AI.pdf\"])\n",
        "documents = reader.load_data()\n",
        "\n",
        "print(f\"Loaded {len(documents)} document(s).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HWY21vPuBdw"
      },
      "source": [
        "#### 2.2: Breaking the data into chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "maOPpR4iis3M"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "# chunk_size of 1024 is a good default value\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "# Create nodes from documents\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJnGnuAZuKzD"
      },
      "source": [
        "#### 2.3 Define the LLM and the Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "3DCnVNCFizXV",
        "outputId": "f3a68650-c4ba-40ac-aa93-a20c99285b97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3294254423.py:6: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
            "  Settings.llm = Gemini(model=\"models/gemini-2.5-flash\")\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "# LLM: Use Gemini, specifying a model like \"models/gemini-pro\" or \"models/gemini-2.5-flash\"\n",
        "Settings.llm = Gemini(model=\"models/gemini-2.5-flash\")\n",
        "\n",
        "# Embedding Model: Use HuggingFaceEmbedding for BGE-small-en\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\" # This is the standard BGE-small-en model name\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZkCDa6UuOgi"
      },
      "source": [
        "#### 2.4 Create the vector index and summary index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aBu3TAWni2Vy"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "\n",
        "# summary index\n",
        "summary_index = SummaryIndex(nodes)\n",
        "# vector store index\n",
        "vector_index = VectorStoreIndex(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOUKB4heuSO_"
      },
      "source": [
        "#### 2.4 Create the vector query engine and summary query engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9l9lVrgNi6Dd"
      },
      "outputs": [],
      "source": [
        "# summary query engine\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "\n",
        "# vector query engine\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEpulllzuWHI"
      },
      "source": [
        "#### 2.5 Convert the vector and query engines into tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UHugM5x-i8Bf"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to the State of AI paper.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context from the the State of AI paper.\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYhHCqoLucC7"
      },
      "source": [
        "#### 2.6 Define a superset query engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LF3YTqDli-FR"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKbSL_tbuflQ"
      },
      "source": [
        "#### 2.7 Test whether the query engine works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "iAA2JIhai_n_",
        "outputId": "c2666efb-4154-4bfb-8624-4e2b78682bce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: The question 'Who is Lareina Yee according to teh document?' asks for a specific piece of information or detail about an individual from the document. This aligns directly with 'retrieving specific context' rather than summarizing the entire paper..\n",
            "\u001b[0mLareina Yee is one of the authors of \"The state of AI\" document.\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"Who is Lareina Yee according to teh document?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjBMU8pwul8P"
      },
      "source": [
        "#### 2.8 Convert the query engine into a tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-xAHwfwqulcO"
      },
      "outputs": [],
      "source": [
        "# Create tool wrapper around router\n",
        "query_engine_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=query_engine,\n",
        "    name=\"state_of_ai_report_assistant\",\n",
        "    description=\"Answers questions based on the McKinsey 2025 State of AI report.\",\n",
        "    return_direct=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcy5m7bYuokd"
      },
      "source": [
        "#### 2.9 Define system prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "adx0Y8UgmJHu"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a helpful assistant specialized in answering questions using the 'State of AI' March 2025 report by McKinsey.\n",
        "Your task is to:\n",
        "\n",
        "1. Use the Summary Tool when the user asks for high-level insights, trends, survey findings, or general understanding\n",
        "   (e.g., \"What are the top AI adoption practices?\" or \"Summarize the report's key findings\").\n",
        "\n",
        "2. Use the Vector Tool when the user is asking for specific statistics, organizational practices, exhibit-based\n",
        "   evidence, or detailed examples\n",
        "   (e.g., \"What percentage of companies track AI KPIs?\" or \"What are the risks companies are mitigating?\").\n",
        "\n",
        "Refer only to the content of the report. If the user's query is outside this context, politely decline or redirect.\n",
        "\n",
        "Check your answer multiple times to make sure it is actually relevant and mentioned in the document.\n",
        "\n",
        "Examples of summary queries:\n",
        "- \"How are companies restructuring to adopt GenAI?\"\n",
        "- \"What does the report say about workforce reskilling?\"\n",
        "\n",
        "Examples of specific/vector queries:\n",
        "- \"What percentage of companies have a roadmap for GenAI adoption?\"\n",
        "- \"Who is responsible for AI governance in large firms?\"\n",
        "\n",
        "Always explain clearly, referencing exact statistics, frameworks, or concepts when relevant. Be concise and insightful.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7xhEtfvut_s"
      },
      "source": [
        "#### 2.10 Define the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bt-1Pnr7jMfK"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent.workflow import AgentWorkflow\n",
        "\n",
        "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
        "    tools_or_functions=[query_engine_tool],\n",
        "    llm=Settings.llm,\n",
        "    system_prompt=system_prompt,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFUqiH8kE3dB"
      },
      "source": [
        "#### 2.11 Setup agent observability using Arize Phoenix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CRE0SnzJeY47",
        "outputId": "dbb2d641-1f1e-4480-9049-4a3d29ad1d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index-callbacks-arize-phoenix\n",
            "  Downloading llama_index_callbacks_arize_phoenix-0.6.1-py3-none-any.whl.metadata (499 bytes)\n",
            "Collecting arize-phoenix\n",
            "  Downloading arize_phoenix-12.7.1-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-callbacks-arize-phoenix) (0.14.5)\n",
            "Collecting openinference-instrumentation-llama-index>=4.1.0 (from llama-index-callbacks-arize-phoenix)\n",
            "  Downloading openinference_instrumentation_llama_index-4.3.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting aioitertools (from arize-phoenix)\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.21.0)\n",
            "Requirement already satisfied: alembic<2,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.17.0)\n",
            "Collecting arize-phoenix-client>=1.20.0 (from arize-phoenix)\n",
            "  Downloading arize_phoenix_client-1.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting arize-phoenix-evals>=2.0.0 (from arize-phoenix)\n",
            "  Downloading arize_phoenix_evals-2.5.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting arize-phoenix-otel>=0.10.3 (from arize-phoenix)\n",
            "  Downloading arize_phoenix_otel-0.13.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.6.5)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (5.5.2)\n",
            "Collecting email-validator (from arize-phoenix)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.119.1)\n",
            "Requirement already satisfied: grpc-interceptor in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.15.4)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.75.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.28.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (3.1.6)\n",
            "Collecting jmespath (from arize-phoenix)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy!=2.0.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.0.2)\n",
            "Collecting openinference-instrumentation>=0.1.32 (from arize-phoenix)\n",
            "  Downloading openinference_instrumentation-0.1.41-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting openinference-semantic-conventions>=0.1.20 (from arize-phoenix)\n",
            "  Downloading openinference_semantic_conventions-0.1.24-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp (from arize-phoenix)\n",
            "  Downloading opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-proto>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.59b0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (3.11.3)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.23.1)\n",
            "Requirement already satisfied: protobuf>=4.25.8 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (5.29.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (22.0.0)\n",
            "Requirement already satisfied: pydantic>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.11.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (2.9.0.post0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.0.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.16.2)\n",
            "Requirement already satisfied: sqlalchemy<3,>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (2.0.44)\n",
            "Collecting sqlean-py>=3.45.1 (from arize-phoenix)\n",
            "  Downloading sqlean_py-3.50.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.48.0)\n",
            "Collecting strawberry-graphql==0.270.1 (from arize-phoenix)\n",
            "  Downloading strawberry_graphql-0.270.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (4.15.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (0.38.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.17.2 in /usr/local/lib/python3.12/dist-packages (from arize-phoenix) (1.17.3)\n",
            "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql==0.270.1->arize-phoenix)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.12/dist-packages (from strawberry-graphql==0.270.1->arize-phoenix) (25.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic<2,>=1.3.0->arize-phoenix) (1.3.10)\n",
            "Collecting jsonpath-ng (from arize-phoenix-evals>=2.0.0->arize-phoenix)\n",
            "  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: opentelemetry-api in /usr/local/lib/python3.12/dist-packages (from arize-phoenix-evals>=2.0.0->arize-phoenix) (1.38.0)\n",
            "Collecting pystache (from arize-phoenix-evals>=2.0.0->arize-phoenix)\n",
            "  Downloading pystache-0.6.8-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (3.13.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (2025.3.0)\n",
            "Requirement already satisfied: llama-index-workflows<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (2.8.3)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (10.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (80.9.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (0.12.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (0.9.0)\n",
            "Collecting opentelemetry-instrumentation (from openinference-instrumentation-llama-index>=4.1.0->llama-index-callbacks-arize-phoenix)\n",
            "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0->arize-phoenix) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.0->arize-phoenix) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.0->arize-phoenix) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.1.0->arize-phoenix) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->arize-phoenix) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=2.0.4->sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (3.2.4)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib->arize-phoenix) (43.0.3)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->arize-phoenix)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator->arize-phoenix) (3.11)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette->arize-phoenix) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->arize-phoenix) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->arize-phoenix) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->arize-phoenix) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->arize-phoenix) (3.0.3)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.38.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.38.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp->arize-phoenix) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp->arize-phoenix) (1.38.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api->arize-phoenix-evals>=2.0.0->arize-phoenix) (8.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->arize-phoenix) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->arize-phoenix) (3.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn->arize-phoenix) (8.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.22.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette->arize-phoenix) (1.3.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.14.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (0.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (2.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib->arize-phoenix) (2.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (3.26.1)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.12/dist-packages (from jsonpath-ng->arize-phoenix-evals>=2.0.0->arize-phoenix) (3.11)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix) (2.23)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api->arize-phoenix-evals>=2.0.0->arize-phoenix) (3.23.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-callbacks-arize-phoenix) (0.4.6)\n",
            "Downloading llama_index_callbacks_arize_phoenix-0.6.1-py3-none-any.whl (3.1 kB)\n",
            "Downloading arize_phoenix-12.7.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading strawberry_graphql-0.270.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arize_phoenix_client-1.21.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arize_phoenix_evals-2.5.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading arize_phoenix_otel-0.13.1-py3-none-any.whl (17 kB)\n",
            "Downloading openinference_instrumentation-0.1.41-py3-none-any.whl (29 kB)\n",
            "Downloading openinference_instrumentation_llama_index-4.3.8-py3-none-any.whl (28 kB)\n",
            "Downloading openinference_semantic_conventions-0.1.24-py3-none-any.whl (10 kB)\n",
            "Downloading sqlean_py-3.50.4.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
            "Downloading pystache-0.6.8-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sqlean-py, pystache, openinference-semantic-conventions, jsonpath-ng, jmespath, graphql-core, dnspython, aioitertools, strawberry-graphql, email-validator, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-http, openinference-instrumentation, opentelemetry-exporter-otlp, openinference-instrumentation-llama-index, arize-phoenix-evals, llama-index-callbacks-arize-phoenix, arize-phoenix-otel, arize-phoenix-client, arize-phoenix\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-http\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-http-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aioitertools-0.12.0 arize-phoenix-12.7.1 arize-phoenix-client-1.21.0 arize-phoenix-evals-2.5.0 arize-phoenix-otel-0.13.1 dnspython-2.8.0 email-validator-2.3.0 graphql-core-3.2.6 jmespath-1.0.1 jsonpath-ng-1.7.0 llama-index-callbacks-arize-phoenix-0.6.1 openinference-instrumentation-0.1.41 openinference-instrumentation-llama-index-4.3.8 openinference-semantic-conventions-0.1.24 opentelemetry-exporter-otlp-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 opentelemetry-instrumentation-0.59b0 pystache-0.6.8 sqlean-py-3.50.4.4 strawberry-graphql-0.270.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "202f8bc8f88e487fb41465b2acf3300a",
              "pip_warning": {
                "packages": [
                  "llama_index",
                  "opentelemetry"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install llama-index-callbacks-arize-phoenix arize-phoenix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jSmLawdeTEN"
      },
      "outputs": [],
      "source": [
        "import llama_index\n",
        "import os\n",
        "\n",
        "PHOENIX_API_KEY = \"\"\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
        "llama_index.core.set_global_handler(\n",
        "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "434C1PNgu2YT"
      },
      "source": [
        "#### 2.12 Run the agent and analyze responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "HxC0y5llE3dB",
        "outputId": "5705c0f0-3ca9-4634-b25c-dae444ee7fc3"
      },
      "outputs": [
        {
          "ename": "InvalidStateError",
          "evalue": "Result is not set.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidStateError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-131118014.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Who is Yareina Lee according to the document? Where is she mentioned in the document and in what context?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_engine_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/workflows/handler.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidStateError\u001b[0m: Result is not set."
          ]
        }
      ],
      "source": [
        "# In Jupyter/Colab, you can use await directly\n",
        "question = \"Who is Yareina Lee according to the document? Where is she mentioned in the document and in what context?\"\n",
        "response = await query_engine_agent.run(question)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PxekjRYu5HV"
      },
      "source": [
        "#### 2.13 Equip the agent with multiple tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1fkBji-joOLP",
        "outputId": "50fac1d7-7f1b-4f18-e627-a5621fba50b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index-tools-arxiv\n",
            "  Downloading llama_index_tools_arxiv-0.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting llama-index-tools-wikipedia\n",
            "  Downloading llama_index_tools_wikipedia-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.0.4-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting arxiv<3.0.0,>=2.1.0 (from llama-index-tools-arxiv)\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-tools-arxiv) (0.12.45)\n",
            "Collecting wikipedia<2.0,>=1.4 (from llama-index-tools-wikipedia)\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Collecting feedparser~=6.0.10 (from arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.0.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (6.0.2)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.14.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.17.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia<2.0,>=1.4->llama-index-tools-wikipedia) (4.13.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.3.8)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv<3.0.0,>=2.1.0->llama-index-tools-arxiv) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.1.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia<2.0,>=1.4->llama-index-tools-wikipedia) (2.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-arxiv) (3.0.2)\n",
            "Downloading llama_index_tools_arxiv-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_index_tools_wikipedia-0.3.0-py3-none-any.whl (2.7 kB)\n",
            "Downloading duckduckgo_search-8.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia, sgmllib3k\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11757 sha256=2f1ddadc8d2536c101f72e20ba288fc4801d6e42c1dc39439d79c7a2004f0ffb\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=2bf5ee7c20de81295d624fad8cf50439ce5987f621922e7315a1ea10806886da\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built wikipedia sgmllib3k\n",
            "Installing collected packages: sgmllib3k, primp, feedparser, wikipedia, duckduckgo-search, arxiv, llama-index-tools-wikipedia, llama-index-tools-arxiv\n",
            "Successfully installed arxiv-2.2.0 duckduckgo-search-8.0.4 feedparser-6.0.11 llama-index-tools-arxiv-0.3.0 llama-index-tools-wikipedia-0.3.0 primp-0.15.0 sgmllib3k-1.0.0 wikipedia-1.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ac88349329834b8091246e616464ae2b",
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index-tools-brave-search\n",
            "  Downloading llama_index_tools_brave_search-0.3.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-tools-brave-search) (0.12.45)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.0.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.14.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.3.8)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (24.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-tools-brave-search) (3.0.2)\n",
            "Downloading llama_index_tools_brave_search-0.3.0-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: llama-index-tools-brave-search\n",
            "Successfully installed llama-index-tools-brave-search-0.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6bb27bc1ee144586bb13f3d430f27c09",
              "pip_warning": {
                "packages": [
                  "llama_index"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install llama-index-tools-arxiv llama-index-tools-wikipedia duckduckgo-search\n",
        "!pip install llama-index-tools-brave-search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16E17tfjvLIx"
      },
      "source": [
        "#### 2.14 Add the new tools (ArXiV, Brave Search)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soxyYOVfoAHB"
      },
      "outputs": [],
      "source": [
        "# Import additional tools\n",
        "from llama_index.tools.arxiv import ArxivToolSpec\n",
        "from llama_index.tools.wikipedia import WikipediaToolSpec\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.tools.brave_search import BraveSearchToolSpec\n",
        "\n",
        "import requests\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2lC5H1SoYpm"
      },
      "outputs": [],
      "source": [
        "# Create ArXiV tool\n",
        "\n",
        "arxiv_tool = ArxivToolSpec()\n",
        "\n",
        "arxiv_tools = arxiv_tool.to_tool_list()\n",
        "\n",
        "\n",
        "# Create Brave Search tool\n",
        "\n",
        "brave_search_tool_spec = BraveSearchToolSpec(api_key=\"\")\n",
        "brave_search_tools = brave_search_tool_spec.to_tool_list()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp0WSiqpodii"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create enhanced agent with multiple tools - FIX: Use extend instead of append\n",
        "enhanced_tools = [query_engine_tool]  # Start with McKinsey report tool\n",
        "enhanced_tools.extend(brave_search_tools)  # Add all brave search tools\n",
        "enhanced_tools.extend(arxiv_tools)  # Add all arxiv tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjWiEqbHvSmE"
      },
      "source": [
        "#### 2.15 Define the enhanced agent with all tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFaTmUITooBF"
      },
      "outputs": [],
      "source": [
        "# Create new enhanced agent\n",
        "enhanced_agent = AgentWorkflow.from_tools_or_functions(\n",
        "    tools_or_functions=enhanced_tools,\n",
        "    llm=Settings.llm,\n",
        "    system_prompt=\"\"\"You are an AI research assistant with access to:\n",
        "    1. The McKinsey 2025 State of AI report\n",
        "    2. Web search capabilities\n",
        "    3. ArXiv research paper search\n",
        "\n",
        "    Use these tools to provide comprehensive, well-researched answers. When discussing AI trends,\n",
        "    combine insights from the McKinsey report with recent research and web findings.\"\"\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31wclWR0vWVJ"
      },
      "source": [
        "#### 2.16 Battle test agent with multiple questions!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvuCQ2GAoqmQ",
        "outputId": "3e0fb64c-3efe-4d8e-ed83-7d338f230f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question 1: Organizational changes and governance\n",
            "==================================================\n",
            "\u001b[1;3;38;5;200mSelecting query engine 0: Summarization questions related to the State of AI paper would likely cover the main organizational changes companies are making for AI adoption..\n",
            "\u001b[0m### Recent Research Papers on AI Governance and Organizational Transformation:\n",
            "\n",
            "#### AI Governance Research Papers:\n",
            "1. **[AI And Organizational Change: Dynamics And Management Strategies](https://www.researchgate.net/publication/380929689_AI_And_Organizational_Change_Dynamics_And_Management_Strategies)**\n",
            "   - This study investigates the dynamics of AI-induced organizational change, focusing on effective change management strategies, employee adaptation, and cultural transformation.\n",
            "\n",
            "2. **[AI in Organizational Change Management — Case Studies, Best Practices, Ethical Implications, and Future Technological Trajectories](https://medium.com/@adnanmasood/ai-in-organizational-change-management-case-studies-best-practices-ethical-implications-and-179be4ec2583)**\n",
            "   - Details the technical and methodological aspects of integrating AI into organizational change, including case studies, best practices, ethical considerations, and future trajectories.\n",
            "\n",
            "3. **[Artificial Intelligence and Organizational Development: Psychological Perspectives on the Restructuring of Organizational Structures, Processes, and Functions](https://www.researchgate.net/publication/381094544_Artificial_Intelligence_and_Organizational_Development_Psychological_Perspectives_on_the_Restructuring_of_Organizational_Structures_Processes_and_Functions)**\n",
            "   - Explores the psychological perspectives on restructuring organizational structures, processes, and functions with the integration of artificial intelligence.\n",
            "\n",
            "#### Organizational Transformation AI Research Papers:\n",
            "1. **[GENERATIVE AI IN CHANGE MANAGEMENT: A NEW FRAMEWORK FOR ORGANIZATIONAL TRANSFORMATION](https://www.researchgate.com/publication/379765500_GENERATIVE_AI_IN_CHANGE_MANAGEMENT_A_NEW_FRAMEWORK_FOR_ORGANIZATIONAL_TRANSFORMATION)**\n",
            "   - Discusses a new framework for organizational transformation using generative AI in change management, emphasizing the importance of effective change management for organizations to adapt and thrive in evolving landscapes.\n",
            "\n",
            "2. **[Navigating the Organizational AI Journey: The AI Transformation Framework](https://www.sciencedirect.com/science/article/abs/pii/S0007681325000023)**\n",
            "   - Presents the AI transformation framework, offering recommendations for practice and highlighting the broad spectrum of changes and adaptations that organizations undergo to leverage the full potential of AI technologies.\n",
            "\n",
            "These research papers provide valuable insights into AI governance, organizational change dynamics, and the integration of AI in driving organizational transformations.\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test questions that can benefit from multiple tools\n",
        "\n",
        "# Question 1: Combine McKinsey insights with recent research\n",
        "question1 = \"\"\"According to the McKinsey report, what are the main organizational changes companies are making for AI adoption?\n",
        "Can you also search for recent research papers on AI governance and organizational transformation to provide additional context?\"\"\"\n",
        "\n",
        "print(\"Question 1: Organizational changes and governance\")\n",
        "print(\"=\" * 50)\n",
        "response1 = await enhanced_agent.run(question1)\n",
        "print(response1)\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-99uMZimpCXj",
        "outputId": "c368957f-5dc5-43ab-f1a7-6ccb8abddd86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question 2: Workflow Redesign\n",
            "\u001b[1;3;38;5;200mSelecting query engine 0: Workflow redesign for AI implementation may involve summarizing key points and recommendations from the State of AI paper..\n",
            "\u001b[0m### ArXiv Papers on Business Process Automation with AI:\n",
            "1. **[D3BA: A Tool for Optimizing Business Processes Using Non-Deterministic Planning](http://arxiv.org/pdf/2001.02619v2):**\n",
            "   - This paper introduces D3BA, a tool for optimizing business processes using AI planning. It focuses on composing services to automate subtasks within complex business processes.\n",
            "\n",
            "2. **[Can Artificial Intelligence Transform DevOps?](http://arxiv.org/pdf/2206.00225v1):**\n",
            "   - Explores the connection between DevOps and AI, highlighting how AI can enhance DevOps processes such as testing, coding, releasing, monitoring, and system improvement.\n",
            "\n",
            "3. **[Impact of Artificial Intelligence on Businesses](http://arxiv.org/pdf/1905.02092v1):**\n",
            "   - Discusses the integration of AI in business processes and its impact on research, innovation, market deployment, and future shifts in business models.\n",
            "\n",
            "### Web Articles on Workflow Transformation:\n",
            "1. **[How Workflow Automation Delivers Business Transformation](https://www.flowforma.com/blog/how-workflow-automation-delivers-business-transformation):**\n",
            "   - Explores workflow automation and its role in delivering business transformation by making processes more intuitive, efficient, and effective.\n",
            "\n",
            "2. **[Workflow Transformation | Buddha Logic](https://buddhalogic.com/solutions/workflow-transformation/):**\n",
            "   - Describes workflow transformation as the process of examining content-focused processes and designing advanced software solutions to enhance efficiency.\n",
            "\n",
            "3. **[Digital Workflow Transformation | Business Process Automation | Kofax](https://www.tungstenautomation.com/workflows):**\n",
            "   - Focuses on automating processes to manage and scale for the future, emphasizing end-to-end digital business workflow transformation.\n",
            "\n",
            "4. **[Workflow > Data Transformation](https://support.medit.com/hc/en-us/articles/360052595291--Workflow-Data-Transformation):**\n",
            "   - Discusses data transformation within workflows, allowing users to adjust data size and scale for various applications.\n",
            "\n",
            "5. **[Why Digital Transformation Starts with Workflows | IBM](https://www.ibm.com/think/insights/why-digital-transformation-starts-with-workflows-that-unite-people-and-technology):**\n",
            "   - Highlights the importance of workflows that unite people and technology in digital transformation, enabling seamless global trade and rapid deployment.\n",
            "\n",
            "These resources provide insights into AI-driven business process optimization and the significance of workflow transformation in achieving business objectives.\n"
          ]
        }
      ],
      "source": [
        "# Question 2: Workflow Redesign and Implementation\n",
        "question2 = \"\"\"What does the McKinsey report say about workflow redesign for AI implementation?\n",
        "Search ArXiv for papers on business process automation with AI and find current web articles about workflow transformation.\"\"\"\n",
        "\n",
        "print(\"Question 2: Workflow Redesign\")\n",
        "response2 = await enhanced_agent.run(question2)\n",
        "print(response2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieLf-4v8qB8C",
        "outputId": "82c79861-d0f4-4b97-9e5a-c80058d5e5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question 3: Risk management\n",
            "\u001b[1;3;38;5;200mSelecting query engine 0: The choice 'Useful for summarization questions related to the State of AI paper' is most relevant as it focuses on summarizing key risks organizations are addressing with gen AI, which aligns with the question asked..\n",
            "\u001b[0m### Recent Academic Research on AI Risk Mitigation:\n",
            "1. **FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation**:\n",
            "   - This research introduces the concept of Data Residual Matching to facilitate data generation and mitigate data information vanishing in dataset distillation tasks. The method significantly improves computational efficiency and achieves superior performance across multiple dataset benchmarks.\n",
            "   - [Read more](http://arxiv.org/pdf/2506.24125v1)\n",
            "\n",
            "2. **Scaling Human Judgment in Community Notes with LLMs**:\n",
            "   - The paper proposes an open ecosystem where both humans and LLMs can write notes, with human raters serving as the ultimate evaluator of helpful notes. This approach accelerates note delivery while maintaining trust and legitimacy.\n",
            "   - [Read more](http://arxiv.org/pdf/2506.24118v1)\n",
            "\n",
            "3. **Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data**:\n",
            "   - Synthetic data is explored as a cost-effective alternative for training artificial neural networks. The study analyzes mixing strategies of synthetic and real data to bridge the domain gap and enhance the robustness and efficacy of training processes.\n",
            "   - [Read more](http://arxiv.org/pdf/2506.24093v1)\n",
            "\n",
            "### Comparison with McKinsey Report Findings:\n",
            "The academic research aligns with the McKinsey report's emphasis on mitigating risks associated with AI. Both sources highlight the importance of addressing data-related risks, improving computational efficiency, and enhancing performance through innovative approaches like data residual matching and hybrid training strategies. Organizations can benefit from integrating these research insights into their risk mitigation strategies to navigate the challenges posed by AI technologies effectively.\n"
          ]
        }
      ],
      "source": [
        "# Question 3: Risk management and future trends\n",
        "question3 = \"\"\"Based on the McKinsey report, what are the key risks organizations are addressing with gen AI?\n",
        "Can you search the web for recent academic research on AI risk mitigation and compare with the report's findings?\"\"\"\n",
        "\n",
        "print(\"Question 3: Risk management\")\n",
        "response3 = await enhanced_agent.run(question3)\n",
        "print(response3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUIlpdi8qB5_",
        "outputId": "c0f08538-4edc-4af9-8553-4cd53fb315d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Comprehensive profile of Lareina Yee\n",
            "============================================================\n",
            "This question should force the agent to use:\n",
            "1. Query Engine - to find info about Lareina Yee in the McKinsey document\n",
            "2. Brave Search - to find recent web articles/news about her\n",
            "3. ArXiv Search - to find any academic papers she's authored\n",
            "============================================================\n",
            "\u001b[1;3;38;5;200mSelecting query engine 1: The question is asking for specific context related to 'Lareina Yee', which would require retrieving specific information from the State of AI paper..\n",
            "\u001b[0m### Lareina Yee Profile:\n",
            "\n",
            "#### McKinsey Global Institute Director:\n",
            "Lareina Yee is a Senior Partner and the Director of the McKinsey Global Institute, where she leads research on AI and frontier technologies, advising companies on growth and transformation.\n",
            "\n",
            "#### Views on AI's Workforce Impact:\n",
            "Lareina Yee's work focuses on understanding the impact of AI on the workforce, particularly in terms of transformation and economic implications.\n",
            "\n",
            "#### Recent Web Findings:\n",
            "1. **[McKinsey Article: Superagency in the Workplace](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)**: Discusses how AI is being used in the workplace in 2025.\n",
            "2. **[McKinsey Article: Preparing for Tomorrow's Agentic Workforce](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/preparing-for-tomorrows-agentic-workforce)**: Mentions Lareina Yee's insights on AI inferencing and its importance.\n",
            "3. **[LinkedIn Profile](https://www.linkedin.com/in/lareinayee/)**: Highlights Lareina Yee's vision for responsible AI research and development.\n",
            "\n",
            "#### Research Papers on ArXiv:\n",
            "1. **[Refinement of Partition Identities by Merca and Yee](http://arxiv.org/pdf/2111.10587v1)**: Refinement and generalization of partition identities by Merca and Yee.\n",
            "2. **[Identities Associated with Mock Theta Functions by Andrews, Dixit, and Yee](http://arxiv.org/pdf/1709.03213v1)**: Defines partition functions related to Ramanujan's mock theta functions.\n",
            "3. **[Combinatorial Proof of an Identity by Andrews and Yee](http://arxiv.org/pdf/1710.10373v2)**: Presents a combinatorial proof of an identity studied by Andrews and Yee.\n",
            "\n",
            "Lareina Yee's expertise lies in AI research, workforce transformation, and economic impact analysis, making significant contributions to understanding the implications of AI on businesses and society.\n"
          ]
        }
      ],
      "source": [
        "# Question that forces usage of all three tools\n",
        "comprehensive_question = \"\"\"Who is Lareina Yee in the McKinsey document and what are her views on AI's workforce impact?\n",
        "\n",
        "After finding information about her from the document, please:\n",
        "1. Search the web using Brave Search for recent articles, interviews, or news about Lareina Yee and her work on AI\n",
        "2. Search ArXiv for any research papers she may have authored or co-authored related to AI, workforce transformation, or economic impact\n",
        "3. Provide a comprehensive profile combining insights from all three sources about her expertise and contributions to AI research\"\"\"\n",
        "\n",
        "print(\"Question: Comprehensive profile of Lareina Yee\")\n",
        "print(\"=\" * 60)\n",
        "print(\"This question should force the agent to use:\")\n",
        "print(\"1. Query Engine - to find info about Lareina Yee in the McKinsey document\")\n",
        "print(\"2. Brave Search - to find recent web articles/news about her\")\n",
        "print(\"3. ArXiv Search - to find any academic papers she's authored\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "response = await enhanced_agent.run(comprehensive_question)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00cf10e3d6e8455980d5066118ea2526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1792fb8e45b04cf2ad2f9b1b7b50c61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "370c33105aa94482a9879cdaa237b3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491b47bff29942c2b3b23cfd222e011f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ac188960dd34f1cbc4d1448ba8a16a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3659927ebaf43e4924886c362426494",
            "placeholder": "​",
            "style": "IPY_MODEL_491b47bff29942c2b3b23cfd222e011f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "5bb095faf6b048388ae1e36c7d7b8796": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf39d22fc1740208697b21add64d72d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "62ce864c960e47d399042ccebf138f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8894971591d948608ecfd50faa1b5d9c",
            "style": "IPY_MODEL_ae34b0dcac484743875ca296b4b8794f",
            "tooltip": ""
          }
        },
        "6d27293639884ff9a84ac607d23d02f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8894971591d948608ecfd50faa1b5d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c237069abef4768b8727054b18a715d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae34b0dcac484743875ca296b4b8794f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "aed853987afa4b93ac1dc6ecffca0ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_5cf39d22fc1740208697b21add64d72d"
          }
        },
        "b4a89ba3925e45eaa8312234ed61da59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be4590a7e2a8482da609231634e01e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9c237069abef4768b8727054b18a715d",
            "placeholder": "​",
            "style": "IPY_MODEL_00cf10e3d6e8455980d5066118ea2526",
            "value": ""
          }
        },
        "c20d9e3006ff40499b37f81a61f6aa21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba09e6dd0a34d47883326221bba0fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_b4a89ba3925e45eaa8312234ed61da59",
            "value": "Connecting..."
          }
        },
        "c3659927ebaf43e4924886c362426494": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15ffdad61ca433d8a73090d6cfae7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_6d27293639884ff9a84ac607d23d02f1",
            "style": "IPY_MODEL_5bb095faf6b048388ae1e36c7d7b8796",
            "value": true
          }
        },
        "fba09e6dd0a34d47883326221bba0fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf66967720648f69ff873988ac17545": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_370c33105aa94482a9879cdaa237b3f1",
            "placeholder": "​",
            "style": "IPY_MODEL_1792fb8e45b04cf2ad2f9b1b7b50c61a",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
